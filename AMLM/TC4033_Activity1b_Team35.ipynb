{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7b82hJRojsn"
      },
      "source": [
        "# Team #35\n",
        "\n",
        "# María Paula Gutiérrez Cervantes - **A01747706**\n",
        "\n",
        "# Juan Miguel Molina Reyes - **A01796655**\n",
        "\n",
        "# Carlos Alberto Rocha Chávez - **A01796914**\n",
        "\n",
        "# Jorge Andrés Santos Gordon - **A01652587**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2ft0_ybom2r"
      },
      "source": [
        "# TC 5033\n",
        "## Deep Learning\n",
        "## Fully Connected Deep Neural Networks\n",
        "\n",
        "#### Activity 1b: Implementing a Fully Connected Network for Kaggle ASL Dataset\n",
        "\n",
        "- Objective\n",
        "\n",
        "The aim of this part of the activity is to apply your understanding of Fully Connected Networks by implementing a multilayer network for the [Kaggle ASL (American Sign Language) dataset](https://www.kaggle.com/datasets/grassknoted/asl-alphabet). While you have been provided with a complete solution for a Fully Connected Network using Numpy for the MNIST dataset, you are encouraged to try to come up with the solution.\n",
        "\n",
        "- Instructions\n",
        "\n",
        "    This activity requires submission in teams of 3 or 4 members. Submissions from smaller or larger teams will not be accepted unless prior approval has been granted (only due to exceptional circumstances). While teamwork is encouraged, each member is expected to contribute individually to the assignment. The final submission should feature the best arguments and solutions from each team member. Only one person per team needs to submit the completed work, but it is imperative that the names of all team members are listed in a Markdown cell at the very beginning of the notebook (either the first or second cell). Failure to include all team member names will result in the grade being awarded solely to the individual who submitted the assignment, with zero points given to other team members (no exceptions will be made to this rule).\n",
        "\n",
        "    Load and Preprocess Data: You are provided a starter code to load the data. Be sure to understand the code.\n",
        "\n",
        "    Review MNIST Notebook (Optional): Before diving into this activity, you have the option to revisit the MNIST example to refresh your understanding of how to build a Fully Connected Network using Numpy.\n",
        "\n",
        "    Start Fresh: Although you can refer to the MNIST solution at any point, try to implement the network for the ASL dataset on your own. This will reinforce your learning and understanding of the architecture and mathematics involved.\n",
        "\n",
        "    Implement Forward and Backward Pass: Write the code to perform the forward and backward passes, keeping in mind the specific challenges and characteristics of the ASL dataset.\n",
        "    \n",
        "     Design the Network: Create the architecture of the Fully Connected Network tailored for the ASL dataset. Choose the number of hidden layers, neurons, and hyperparameters judiciously.\n",
        "\n",
        "    Train the Model: Execute the training loop, ensuring to track performance metrics such as loss and accuracy.\n",
        "\n",
        "    Analyze and Document: Use Markdown cells to document in detail the choices you made in terms of architecture and hyperparameters, you may use figures, equations, etc to aid in your explanations. Include any metrics that help justify these choices and discuss the model's performance.  \n",
        "\n",
        "- Evaluation Criteria\n",
        "\n",
        "    - Code Readability and Comments\n",
        "    - Appropriateness of chosen architecture and hyperparameters for the ASL dataset\n",
        "    - Performance of the model on the ASL dataset (at least 70% acc)\n",
        "    - Quality of Markdown documentation\n",
        "\n",
        "- Submission\n",
        "\n",
        "Submit this Jupyter Notebook in canvas with your complete solution, ensuring your code is well-commented and includes Markdown cells that explain your design choices, results, and any challenges you encountered.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Implementation"
      ],
      "metadata": {
        "id": "kpfij1rO8WbE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The first step in the solution is to import several libraries, that will be used to build the functions. We import numpy and pandas for data structures and handling, as well as matplotlib for plotting examples, and sklearn for the splitting of the validation set.*"
      ],
      "metadata": {
        "id": "BhvlK-kz7nN8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "fac_YvmQohdC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import string\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*As we are working with a Jupyter Notebook in Google Colab, the files will be temporarily uploaded to the content folder of Colab to read from directly. We have to set the path for both the Train and Validation datasets, and read them using the standard .read_csv function offered by pandas*"
      ],
      "metadata": {
        "id": "DIDNqEww74cP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "PQbZoENhoq9d"
      },
      "outputs": [],
      "source": [
        "TRAIN_PATH = '/content/sign_mnist_train.csv'\n",
        "VALID_PATH = '/content/sign_mnist_valid.csv'\n",
        "train_df = pd.read_csv(TRAIN_PATH)\n",
        "valid_df = pd.read_csv(VALID_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*As a good practice, we print the first 5 rows of the dataset to get a better understanding of the data. It has 785 columns, which represent 784 pixels and the label (letter of the alphabet based on an index)*"
      ],
      "metadata": {
        "id": "a26fqBRG8djR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "4jUh1jaPorvf",
        "outputId": "4a32968c-7a65-4c98-af22-d5232a912996"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0      3     107     118     127     134     139     143     146     150   \n",
              "1      6     155     157     156     156     156     157     156     158   \n",
              "2      2     187     188     188     187     187     186     187     188   \n",
              "3      2     211     211     212     212     211     210     211     210   \n",
              "4     12     164     167     170     172     176     179     180     184   \n",
              "\n",
              "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0     153  ...       207       207       207       207       206       206   \n",
              "1     158  ...        69       149       128        87        94       163   \n",
              "2     187  ...       202       201       200       199       198       199   \n",
              "3     210  ...       235       234       233       231       230       226   \n",
              "4     185  ...        92       105       105       108       133       163   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0       206       204       203       202  \n",
              "1       175       103       135       149  \n",
              "2       198       195       194       195  \n",
              "3       225       222       229       163  \n",
              "4       157       163       164       179  \n",
              "\n",
              "[5 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eac101ad-2cb2-43ff-9e45-26d5b997b68c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>107</td>\n",
              "      <td>118</td>\n",
              "      <td>127</td>\n",
              "      <td>134</td>\n",
              "      <td>139</td>\n",
              "      <td>143</td>\n",
              "      <td>146</td>\n",
              "      <td>150</td>\n",
              "      <td>153</td>\n",
              "      <td>...</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>155</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>158</td>\n",
              "      <td>158</td>\n",
              "      <td>...</td>\n",
              "      <td>69</td>\n",
              "      <td>149</td>\n",
              "      <td>128</td>\n",
              "      <td>87</td>\n",
              "      <td>94</td>\n",
              "      <td>163</td>\n",
              "      <td>175</td>\n",
              "      <td>103</td>\n",
              "      <td>135</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>187</td>\n",
              "      <td>186</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>...</td>\n",
              "      <td>202</td>\n",
              "      <td>201</td>\n",
              "      <td>200</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>195</td>\n",
              "      <td>194</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>211</td>\n",
              "      <td>211</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>210</td>\n",
              "      <td>...</td>\n",
              "      <td>235</td>\n",
              "      <td>234</td>\n",
              "      <td>233</td>\n",
              "      <td>231</td>\n",
              "      <td>230</td>\n",
              "      <td>226</td>\n",
              "      <td>225</td>\n",
              "      <td>222</td>\n",
              "      <td>229</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12</td>\n",
              "      <td>164</td>\n",
              "      <td>167</td>\n",
              "      <td>170</td>\n",
              "      <td>172</td>\n",
              "      <td>176</td>\n",
              "      <td>179</td>\n",
              "      <td>180</td>\n",
              "      <td>184</td>\n",
              "      <td>185</td>\n",
              "      <td>...</td>\n",
              "      <td>92</td>\n",
              "      <td>105</td>\n",
              "      <td>105</td>\n",
              "      <td>108</td>\n",
              "      <td>133</td>\n",
              "      <td>163</td>\n",
              "      <td>157</td>\n",
              "      <td>163</td>\n",
              "      <td>164</td>\n",
              "      <td>179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eac101ad-2cb2-43ff-9e45-26d5b997b68c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eac101ad-2cb2-43ff-9e45-26d5b997b68c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eac101ad-2cb2-43ff-9e45-26d5b997b68c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*To separate the label from the inputs, we create new y_train/val arrays, taking the only the \"label\" column from the original datasets. Afterwards, we delete the \"label\" column from the original arrays. Finally, we create the x/input dataframe using the astype command, which allows us to make the switch from pandas to numpy, making sure all values are converte to a 32-bit float number.*"
      ],
      "metadata": {
        "id": "zFwqUdlX8uk5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "eDxi8LhcotdF"
      },
      "outputs": [],
      "source": [
        "y_train = np.array(train_df['label'])\n",
        "y_val = np.array(valid_df['label'])\n",
        "del train_df['label']\n",
        "del valid_df['label']\n",
        "x_train = train_df.values.astype(np.float32)\n",
        "x_val = valid_df.values.astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*At this point we only have two sets (train and validation). However, it is important to have a test set as well, that will provide the final metrics to measure the performance of the model. Using the train_test_split function from sklearn, we create a split_val_test function that takes x and y (data arrays) as arguments, a fixed pct of 0.5, and a shuffle of true, and returns those datesets divided into 4 datasets of equal size (x & y for test & validation). Later on, we call the function, sending the x_val and y_val datasets as arguments.*"
      ],
      "metadata": {
        "id": "u923v_hV-V9X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "VykWOMhHoxrb"
      },
      "outputs": [],
      "source": [
        "def split_val_test(x, y, pct=0.5, shuffle=True):\n",
        "    x_val, x_test, y_val, y_test = train_test_split(x, y, test_size=pct, random_state=42)\n",
        "    return x_val, x_test, y_val, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "ZSZjmaoPo1YK"
      },
      "outputs": [],
      "source": [
        "x_val, x_test, y_val, y_test = split_val_test(x_val, y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*As we will be working with labels that represent letters of the alphabet, we import a list of letters from the string library, which pulls the ascii values. The ASL dataset doesn't include j or z, which is why those letters are removed from the list. We print the length of the alphabet list, which outputs a 24 (26 letters minus the 2 that were removed).*"
      ],
      "metadata": {
        "id": "TsHH78PX_A2G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO1hAeOlo4A5",
        "outputId": "1384b942-86f1-407c-8906-0fd9ba0a0e4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n"
          ]
        }
      ],
      "source": [
        "alphabet=list(string.ascii_lowercase)\n",
        "alphabet.remove('j')\n",
        "alphabet.remove('z')\n",
        "print(len(alphabet))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZbhAbtEo7BV"
      },
      "source": [
        "### Normalise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Neural networks, specially those with He initialization, have very small values in their weights. Our inputs represent pixels, which range fro, 0 to 255 in value. If we don't normalise the values of the inputs, the result of the operations can fail due to lack of stability. In order to normalise, we first visualize the mean and standard deviation of the x_train array. We then define a normalise function, that takes a calculation of mean and standard deviation, and an array to be altered. In the function, the mean is substracted from the datapoints, and this is divided by the standard deviation. In term, this allows us to have a mean of 0 and a standard deviation of 1, which ensures that all values are between -1 and 1. We call the function on each of the 3 input arrays (train, test and validation), and do a final calculation of the mean and standard deviation to confirm the results are as expected.*"
      ],
      "metadata": {
        "id": "8neVoP_c_hnS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJDoNNRTo4kC",
        "outputId": "bbc36ae3-c374-48cd-e796-ba48350069e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float32(159.29083), np.float32(48.76953), np.float32(0.0))"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "x_train.mean(), x_train.std(), x_train.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "jLNk3MN-pNF1"
      },
      "outputs": [],
      "source": [
        "def normalise(x_mean, x_std, x_data):\n",
        "    return (x_data - x_mean) / x_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "laiSaD9ppOSp"
      },
      "outputs": [],
      "source": [
        "x_mean = x_train.mean()\n",
        "x_std = x_train.std()\n",
        "\n",
        "x_train = normalise(x_mean, x_std, x_train)\n",
        "x_val = normalise(x_mean, x_std, x_val)\n",
        "x_test = normalise(x_mean, x_std, x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2IFAF-SpPja",
        "outputId": "b86f4b1d-7577-49d8-be49-a4b1b815a92a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float32(3.6268384e-06), np.float32(0.99999946))"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "x_train.mean(), x_train.std()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKfuobyXpRJN"
      },
      "source": [
        "### Plotting samples"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*To get a first glimpse of samples, we need to plot a row/image of the dataset. We define a plot_number function, which takes an image as argument. We initialize a matplotlib plot, and using the imshow function, display it. When calling the function, we generate a random index (from 0 to the lenght of the test array), and we get the value of the label of that row. We use this value as a further index to get the corresponding value in the alphabet list and print it. Finally, we call the original index from the x_test dataset, and reshape it from 784 to 28x28, which are the dimensions of the image.*"
      ],
      "metadata": {
        "id": "jQJZzpPZAziR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "XBKg3y4jpTVU"
      },
      "outputs": [],
      "source": [
        "def plot_number(image):\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "Ol7Q3UYEpUoZ",
        "outputId": "ac499a22-03fe-41ab-ea1b-26ea8123f9a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image shown represents letter : b\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "idx = np.random.randint(len(y_test))\n",
        "print(f'The image shown represents letter : {alphabet[y_test[idx]]}')\n",
        "plot_number(x_test[idx].reshape(28,28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwEjmHxSpXjW"
      },
      "source": [
        "### Model equations\n",
        "\n",
        "\n",
        "$$z^1 = W^1 X + b^1$$\n",
        "\n",
        "$$a^1 = ReLU(z^1) $$\n",
        "\n",
        "$$z^2 = W^2 a^1 + b^2$$\n",
        "\n",
        "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
        "\n",
        "\n",
        "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
        "\n",
        "\n",
        "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDqIVc5jpmC-"
      },
      "source": [
        "### ReLU Class"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The first step to create the NN is to define the ReLU functions. We will use ReLU as the activation algorithm, and mathematically, it allows all positive values to pass as they are, and turns all negative values to 0. This could be thought as getting the maximum of the value and 0, and in the corresponding function, we use the np.maximum function to declare this.*\n",
        "\n",
        "*When building the ReLU function for the backpropagation, we have to take Z (the output of the current layer before activation) and dA (the gradient of the next layer). dZ (the gradient of the current layer) is simply a copy of dA. A similar activation is done, where all indexes where Z was less than 0 are turned into a 0, effectively removing the gradient.*"
      ],
      "metadata": {
        "id": "SdL2UMfBB1PN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "sW8LBoSLpV07"
      },
      "outputs": [],
      "source": [
        "def relu(Z):\n",
        "  return np.maximum(0, Z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "E1prhDLxps61"
      },
      "outputs": [],
      "source": [
        "def reluBack(Z, dA):\n",
        "  dZ = dA.copy()\n",
        "  dZ[Z <= 0] = 0\n",
        "  return dZ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrCHPHGHp1Lb"
      },
      "source": [
        "###  Linear Class"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Next up is the linear class, which computes the main operation of the perceptron. The forward function is straightforward, as it is only the calculation of W (weights)* **X (inputs) + b (biases).*\n",
        "\n",
        "*For the backward pass, we need to take the weights and inputs, as well as dZ (the gradient of the current layer). To get the gradient of the Weights (dW), we multpily dZ times the X array (transposed). To get the gradient of the Biases (db), we get the sum of the gradients stored in dZ. Finally, to get the gradient of the inputs (dX), we multiply the Weights array (transposed) times the gradients stored in dZ.*"
      ],
      "metadata": {
        "id": "WLqzPsH1DzRa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "99_8Z0z0p39X"
      },
      "outputs": [],
      "source": [
        "def linear(X, W, b):\n",
        "    Z = W @ X + b\n",
        "    return Z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "mT9Auddfp9Kq"
      },
      "outputs": [],
      "source": [
        "def linearBack(X, W, dZ):\n",
        "\n",
        "    dW = (dZ @ X.T)\n",
        "    db = np.sum(dZ, axis=1, keepdims=True)\n",
        "    dX = W.T @ dZ\n",
        "\n",
        "    return dX, dW, db"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNx39Nopprzv"
      },
      "source": [
        "### Cost Function"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The next step is to define the cost function, which uses Softmax and Cross Entropy as basis. Here, we get two inputs, the results from the forward calculations, and y, the labels. First, we get the size of the batch (how many rows were computed). We first get the exponential value of the calculations, but with a caveat. To avoid the calculations from overflowing, we substract the highest value within the calculations from every row, and apply the exponential to that result. Then, we calculate the probability of each of the 24 labels by dividing the result of the exponential between the sum of all the exponential values of the row.*\n",
        "\n",
        "*Next, we calculate the probability of the correct class for each row, which is commonly referred to as loss. We initizalize dZ (the gradient that will be the first used in the backpropagation process) as a copy of probs, and substract 1 from the correct label for each row. Finally, we normalize the values by dividing dZ between the batch size.*"
      ],
      "metadata": {
        "id": "BD1iN-XSGy03"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "H1umNL1TqHEQ"
      },
      "outputs": [],
      "source": [
        "def softmaxXEntropy(calc, y):\n",
        "    batch_size = calc.shape[1]\n",
        "\n",
        "    exp = np.exp(calc - np.max(calc, axis=0, keepdims=True))\n",
        "    probs = exp / np.sum(exp, axis=0, keepdims=True)\n",
        "\n",
        "    loss = -np.mean(np.log(probs[y, np.arange(batch_size)]))\n",
        "\n",
        "    dZ = probs\n",
        "    dZ[y, np.arange(batch_size)] -= 1\n",
        "    dZ /= batch_size\n",
        "\n",
        "    return loss, dZ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1K5AaI7qGhl"
      },
      "source": [
        "### Model Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*With the functions defined, we need to initialize the model. Although a flexible approach can be taken to add and declare the number of layers in each run, for this example these values will be fixed. In this case, we want to build a medium sized network (without falling into the deep category), which usually have 2 or 3 layers. For this exercise, 2 hidden layers will be employed, as the accuracy we are targeting is around 70%. In order to define the number of neurons in the layers, it is a common practice to use the number of inputs* **0.3, or the average of inputs + number of classes.*\n",
        "\n",
        "*Carrying out these calculations gives us results of:*\n",
        "\n",
        "*784* * *0.3 = 235.2*\n",
        "\n",
        "*(784 + 24)/2 = 404*\n",
        "\n",
        "*In NNs, powers of 2 are always preferred for computational efficiency. As we need to define the number of neurons for 2 layers, we can take the closests powers to the results we got, which would be 512 and 256. In this case, the network would go from 784 > 512 > 256 > 24, which is a gradual enough reduction of dimensions. We start the model as an empty dictionary, and slowly add the weights and biases lists for each layer. In the case of the biases, we initialize them as zeros, and for the weights, we use a He initialization, which consists of first assigning random values that have a standard normal distribution, and then mulitplying it by the square root of (2/the number of inputs).*"
      ],
      "metadata": {
        "id": "TMQ-omDEJkyf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "TxmMMB7cqT9O"
      },
      "outputs": [],
      "source": [
        "def init_model():\n",
        "    model = {}\n",
        "\n",
        "    model['W1'] = np.random.randn(512, 784) * np.sqrt(2 / 784)\n",
        "    model['b1'] = np.zeros((512, 1))\n",
        "\n",
        "    model['W2'] = np.random.randn(256, 512) * np.sqrt(2 / 512)\n",
        "    model['b2'] = np.zeros((256, 1))\n",
        "\n",
        "    model['W3'] = np.random.randn(24, 256) * np.sqrt(2 / 256)\n",
        "    model['b3'] = np.zeros((24, 1))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhcjeh9yqUf4"
      },
      "source": [
        "### Forward & Backward pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The next step is to compute the forward pass for each layer. To do the linear pass, we simply call the linear function, sending the weights and biases of the current step as arguments. In between each layer, the result is used as an argument when calling the relu function defined earlier, but the last layer will not have ReLU activation. We save the results for each output and activation in a temporary list. All results are stored and returned.*\n",
        "\n",
        "*A similar process is done for the backwards linear passes, by calling the backward linear function and the backward ReLU function alternating. In the linear, we send the results from the previous layers, along with the gradients and weights of the current step. In the ReLU, we send the current values and gradients.*\n",
        "\n",
        "*Finally, we perform an update of the weights and biases, by substracting the value of the corresponding gradients, multiplied by the learning rate. This helps us control how fast/slow the gradient changes.*"
      ],
      "metadata": {
        "id": "06tEzoCUMmhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(model, X):\n",
        "    Z1 = linear(X, model['W1'], model['b1'])\n",
        "    A1 = relu(Z1)\n",
        "\n",
        "    Z2 = linear(A1, model['W2'], model['b2'])\n",
        "    A2 = relu(Z2)\n",
        "\n",
        "    Z3 = linear(A2, model['W3'], model['b3'])\n",
        "\n",
        "    temp = (X, Z1, A1, Z2, A2)\n",
        "    return Z3, temp"
      ],
      "metadata": {
        "id": "2bcYdJhKPD_S"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward(model, temp, dZ3):\n",
        "    X, Z1, A1, Z2, A2 = temp\n",
        "\n",
        "    #Linear3\n",
        "    dA2, dW3, db3 = linearBack(A2, model['W3'], dZ3)\n",
        "\n",
        "    #ReLU2\n",
        "    dZ2 = reluBack(Z2, dA2)\n",
        "\n",
        "    #Linear2\n",
        "    dA1, dW2, db2 = linearBack(A1, model['W2'], dZ2)\n",
        "\n",
        "    #ReLU1\n",
        "    dZ1 = reluBack(Z1, dA1)\n",
        "\n",
        "    #Linear1\n",
        "    dA, dW1, db1 = linearBack(X, model['W1'], dZ1)\n",
        "\n",
        "    grads = {\n",
        "        'dW1': dW1,\n",
        "        'db1': db1,\n",
        "        'dW2': dW2,\n",
        "        'db2': db2,\n",
        "        'dW3': dW3,\n",
        "        'db3': db3\n",
        "    }\n",
        "\n",
        "    return grads\n"
      ],
      "metadata": {
        "id": "3XZTGab2NfQL"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "DEA7JyvIquqH"
      },
      "outputs": [],
      "source": [
        "def update(model, grads, lr):\n",
        "    model['W1'] -= lr * grads['dW1']\n",
        "    model['b1'] -= lr * grads['db1']\n",
        "    model['W2'] -= lr * grads['dW2']\n",
        "    model['b2'] -= lr * grads['db2']\n",
        "    model['W3'] -= lr * grads['dW3']\n",
        "    model['b3'] -= lr * grads['db3']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_udtm1lq4XP"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*One of the last steps is to define the training loop. This loop takes the model and the X/y arrays as inputs, along with some other values, which include the number of epochs (times it will be trained), batch_size (how many rows will be computed in each pass) and the learning rate. The function will have 2 nested for loops:*\n",
        "\n",
        "*The first loop runs in a range of epochs (number of training cycles), and the second one runs from 0 to the number of rows in the X array, in increments of the size of the batch. We define small x and y arrays (that are the size of the batches), by taking the indexes starting from the current value of i, until i + size of batch.*\n",
        "\n",
        "*Within the loop, we call the forward, backward and cost functions, along with the update function. Finally, we print the number of the training step, the calculated loss, and the accuracy of the current step based on the validation.*\n",
        "\n",
        "*The accuracy function is calculated by calling the forward function, and predicting the correct classification rows. We make an average, considering only the cases when the prediction is equal to the real result.*"
      ],
      "metadata": {
        "id": "cGyY7nbIRZhp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "O1GhJzl7q3rA"
      },
      "outputs": [],
      "source": [
        "def train(model, X, y, epochs, batch_size, lr):\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(0, X.shape[0], batch_size):\n",
        "            xb = X[i:i+batch_size].T\n",
        "            yb = y[i:i+batch_size]\n",
        "\n",
        "            calc, temp = forward(model, xb)\n",
        "            loss, dZ3 = softmaxXEntropy(calc, yb)\n",
        "            grads = backward(model, temp, dZ3)\n",
        "            update(model, grads, lr)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss:.4f}, Accuracy: {accuracy(model, x_val, y_val)}\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "eQYANsVfq8g3"
      },
      "outputs": [],
      "source": [
        "def accuracy(model, X, y):\n",
        "    Z3, _ = forward(model, X.T)\n",
        "    preds = np.argmax(Z3, axis=0)\n",
        "    return np.mean(preds == y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*In order to run the code, we first need to create an instance of the model, by calling the init_model function. Finally, we can use this as an input in the train function. The 3 other arguments were decided as follows:*\n",
        "\n",
        "*Epochs: When running tests, we saw that the accuracy rocketed during the first 25 training loops, and then slowly improved afterwards. After 50 epochs, the improvement was still visible, but increments were very small. In the end, 100 epochs were the best choice, as we were able to balance the benefits and improvements of the model, without really overfitting the model*\n",
        "\n",
        "*Batch Size: As with the number of neurons, a base 2 batch size is preferred. Our training dataset consists of 27455 images, so a batch size of 128 would result in a little more than 214 passes in each run. This batch size is large enough to have a smooth gradient descent, and small enough to not be to computationally expensive either.*\n",
        "\n",
        "*Learning rate: We chose a value of 1e-3, which is standard for neural networks. This value pairs well with the batch size selected, and allows the loss to decrease fast enough, without it becoming unstable at any given moment.*"
      ],
      "metadata": {
        "id": "zKO-L5SaZJf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelInitial = init_model()"
      ],
      "metadata": {
        "id": "luDC2ZodvgUY"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlpfIWumtJle",
        "outputId": "e9097be2-77a6-42bf-eef6-de1dee948426"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.9100, Accuracy: 0.177356385945343\n",
            "Epoch 2, Loss: 2.4347, Accuracy: 0.2802565532626882\n",
            "Epoch 3, Loss: 2.0941, Accuracy: 0.36391522587841607\n",
            "Epoch 4, Loss: 1.8407, Accuracy: 0.4255437813720022\n",
            "Epoch 5, Loss: 1.6451, Accuracy: 0.46848856664807587\n",
            "Epoch 6, Loss: 1.4892, Accuracy: 0.4986056887897379\n",
            "Epoch 7, Loss: 1.3597, Accuracy: 0.5270496374790853\n",
            "Epoch 8, Loss: 1.2502, Accuracy: 0.5446179587283881\n",
            "Epoch 9, Loss: 1.1540, Accuracy: 0.5591187953151143\n",
            "Epoch 10, Loss: 1.0701, Accuracy: 0.5738984941438929\n",
            "Epoch 11, Loss: 0.9956, Accuracy: 0.5856107083100948\n",
            "Epoch 12, Loss: 0.9279, Accuracy: 0.596207473508087\n",
            "Epoch 13, Loss: 0.8666, Accuracy: 0.6087562744004462\n",
            "Epoch 14, Loss: 0.8111, Accuracy: 0.617122141662019\n",
            "Epoch 15, Loss: 0.7604, Accuracy: 0.628276631344116\n",
            "Epoch 16, Loss: 0.7143, Accuracy: 0.6366424986056888\n",
            "Epoch 17, Loss: 0.6722, Accuracy: 0.6411042944785276\n",
            "Epoch 18, Loss: 0.6335, Accuracy: 0.647239263803681\n",
            "Epoch 19, Loss: 0.5982, Accuracy: 0.6517010596765198\n",
            "Epoch 20, Loss: 0.5663, Accuracy: 0.6553262688232013\n",
            "Epoch 21, Loss: 0.5370, Accuracy: 0.6631344116006692\n",
            "Epoch 22, Loss: 0.5102, Accuracy: 0.6687116564417178\n",
            "Epoch 23, Loss: 0.4855, Accuracy: 0.6737311767986615\n",
            "Epoch 24, Loss: 0.4630, Accuracy: 0.6759620747350809\n",
            "Epoch 25, Loss: 0.4421, Accuracy: 0.6812604573340769\n",
            "Epoch 26, Loss: 0.4225, Accuracy: 0.6834913552704964\n",
            "Epoch 27, Loss: 0.4041, Accuracy: 0.6882320133853876\n",
            "Epoch 28, Loss: 0.3869, Accuracy: 0.690462911321807\n",
            "Epoch 29, Loss: 0.3707, Accuracy: 0.6938092582264361\n",
            "Epoch 30, Loss: 0.3555, Accuracy: 0.6960401561628555\n",
            "Epoch 31, Loss: 0.3411, Accuracy: 0.6977133296151701\n",
            "Epoch 32, Loss: 0.3275, Accuracy: 0.7005019520356943\n",
            "Epoch 33, Loss: 0.3148, Accuracy: 0.702175125488009\n",
            "Epoch 34, Loss: 0.3028, Accuracy: 0.7038482989403235\n",
            "Epoch 35, Loss: 0.2915, Accuracy: 0.7066369213608478\n",
            "Epoch 36, Loss: 0.2807, Accuracy: 0.7085889570552147\n",
            "Epoch 37, Loss: 0.2704, Accuracy: 0.7110987172336866\n",
            "Epoch 38, Loss: 0.2606, Accuracy: 0.7138873396542108\n",
            "Epoch 39, Loss: 0.2512, Accuracy: 0.7169548243167875\n",
            "Epoch 40, Loss: 0.2422, Accuracy: 0.7183491355270496\n",
            "Epoch 41, Loss: 0.2336, Accuracy: 0.7197434467373117\n",
            "Epoch 42, Loss: 0.2255, Accuracy: 0.7219743446737312\n",
            "Epoch 43, Loss: 0.2177, Accuracy: 0.7222532069157837\n",
            "Epoch 44, Loss: 0.2104, Accuracy: 0.7228109313998885\n",
            "Epoch 45, Loss: 0.2034, Accuracy: 0.7255995538204127\n",
            "Epoch 46, Loss: 0.1967, Accuracy: 0.7267150027886224\n",
            "Epoch 47, Loss: 0.1903, Accuracy: 0.7278304517568321\n",
            "Epoch 48, Loss: 0.1841, Accuracy: 0.7286670384829894\n",
            "Epoch 49, Loss: 0.1783, Accuracy: 0.7306190741773564\n",
            "Epoch 50, Loss: 0.1727, Accuracy: 0.7314556609035137\n",
            "Epoch 51, Loss: 0.1673, Accuracy: 0.7322922476296709\n",
            "Epoch 52, Loss: 0.1622, Accuracy: 0.7328499721137758\n",
            "Epoch 53, Loss: 0.1574, Accuracy: 0.7339654210819855\n",
            "Epoch 54, Loss: 0.1527, Accuracy: 0.7345231455660903\n",
            "Epoch 55, Loss: 0.1482, Accuracy: 0.7350808700501952\n",
            "Epoch 56, Loss: 0.1439, Accuracy: 0.7353597322922476\n",
            "Epoch 57, Loss: 0.1398, Accuracy: 0.7361963190184049\n",
            "Epoch 58, Loss: 0.1358, Accuracy: 0.7370329057445622\n",
            "Epoch 59, Loss: 0.1320, Accuracy: 0.7370329057445622\n",
            "Epoch 60, Loss: 0.1283, Accuracy: 0.7381483547127718\n",
            "Epoch 61, Loss: 0.1248, Accuracy: 0.7392638036809815\n",
            "Epoch 62, Loss: 0.1214, Accuracy: 0.7392638036809815\n",
            "Epoch 63, Loss: 0.1182, Accuracy: 0.7403792526491912\n",
            "Epoch 64, Loss: 0.1151, Accuracy: 0.741494701617401\n",
            "Epoch 65, Loss: 0.1122, Accuracy: 0.7426101505856108\n",
            "Epoch 66, Loss: 0.1093, Accuracy: 0.7437255995538204\n",
            "Epoch 67, Loss: 0.1066, Accuracy: 0.7442833240379253\n",
            "Epoch 68, Loss: 0.1039, Accuracy: 0.7451199107640826\n",
            "Epoch 69, Loss: 0.1014, Accuracy: 0.745398773006135\n",
            "Epoch 70, Loss: 0.0989, Accuracy: 0.7462353597322923\n",
            "Epoch 71, Loss: 0.0965, Accuracy: 0.7462353597322923\n",
            "Epoch 72, Loss: 0.0942, Accuracy: 0.7462353597322923\n",
            "Epoch 73, Loss: 0.0920, Accuracy: 0.7462353597322923\n",
            "Epoch 74, Loss: 0.0899, Accuracy: 0.7462353597322923\n",
            "Epoch 75, Loss: 0.0878, Accuracy: 0.7462353597322923\n",
            "Epoch 76, Loss: 0.0858, Accuracy: 0.7462353597322923\n",
            "Epoch 77, Loss: 0.0839, Accuracy: 0.7467930842163971\n",
            "Epoch 78, Loss: 0.0821, Accuracy: 0.7470719464584495\n",
            "Epoch 79, Loss: 0.0803, Accuracy: 0.7484662576687117\n",
            "Epoch 80, Loss: 0.0786, Accuracy: 0.7493028443948689\n",
            "Epoch 81, Loss: 0.0769, Accuracy: 0.7495817066369214\n",
            "Epoch 82, Loss: 0.0753, Accuracy: 0.7498605688789738\n",
            "Epoch 83, Loss: 0.0738, Accuracy: 0.7501394311210262\n",
            "Epoch 84, Loss: 0.0723, Accuracy: 0.7509760178471835\n",
            "Epoch 85, Loss: 0.0708, Accuracy: 0.7512548800892359\n",
            "Epoch 86, Loss: 0.0694, Accuracy: 0.7518126045733408\n",
            "Epoch 87, Loss: 0.0681, Accuracy: 0.7523703290574456\n",
            "Epoch 88, Loss: 0.0668, Accuracy: 0.7534857780256553\n",
            "Epoch 89, Loss: 0.0655, Accuracy: 0.754601226993865\n",
            "Epoch 90, Loss: 0.0643, Accuracy: 0.754601226993865\n",
            "Epoch 91, Loss: 0.0631, Accuracy: 0.7551589514779699\n",
            "Epoch 92, Loss: 0.0620, Accuracy: 0.7554378137200223\n",
            "Epoch 93, Loss: 0.0608, Accuracy: 0.7557166759620747\n",
            "Epoch 94, Loss: 0.0598, Accuracy: 0.7557166759620747\n",
            "Epoch 95, Loss: 0.0587, Accuracy: 0.756553262688232\n",
            "Epoch 96, Loss: 0.0577, Accuracy: 0.7568321249302844\n",
            "Epoch 97, Loss: 0.0567, Accuracy: 0.7573898494143892\n",
            "Epoch 98, Loss: 0.0557, Accuracy: 0.7576687116564417\n",
            "Epoch 99, Loss: 0.0548, Accuracy: 0.7579475738984941\n",
            "Epoch 100, Loss: 0.0539, Accuracy: 0.7582264361405465\n"
          ]
        }
      ],
      "source": [
        "train(modelInitial, x_train, y_train, epochs=100, batch_size=128, lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*To test the final accuracy of the model, we call the accuracy function, but this time sending the test arrays, as this is data the model hasn't seen before. In different runs, we have gotten a final accuracy between 75% and 80%, which passes the 70% benchmark established at the beginning of the exercise*"
      ],
      "metadata": {
        "id": "q4kqD462Xux7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "iLv9nmX6tZ11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1597384-2604-4dc3-cf5e-44fdaeb862a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.7721695482431679)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "accuracy(modelInitial, x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Finally, we can compute some tests to compare the prediction with the actual value, calling the forward method with only one row of the test array, and printing the result based on the alphabet list. We also print the real value (taken from the actual y_test list), to compare the two.*"
      ],
      "metadata": {
        "id": "S5oAxZ9MYGOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.randint(len(y_test))\n",
        "plot_number(x_test[idx].reshape(28,28))\n",
        "calc, _ = forward(modelInitial, x_test[idx].reshape(-1, 1))\n",
        "pred = np.argmax(calc, axis=0)[0]\n",
        "\n",
        "print(f'The predicted value is : {alphabet[pred]}')\n",
        "print(f'The real value is : {alphabet[y_test[idx]]}')"
      ],
      "metadata": {
        "id": "vU9CjpghwnxR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "28c2c504-b393-486b-abd4-91dec1ddc7bc"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted value is : i\n",
            "The real value is : i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2djholoAD8b6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this activity, we were able to design and implement a fully connected deep neural network using NumPy for image classification on Kaggle's ASL dataset. The data was preprocessed carefully by splitting the data into two separate labels, normalizing the input features, and creating proper training, validation, and test splits to ensure appropriate evaluation.\n",
        "\n",
        "For the network architecture, two hidden layers with ReLU activation functions were implemented along with He initialization. This helped to keep the network's training stable and ensure effective gradient flow. We also trained the model using mini-batch gradient descent and further optimized it with a softmax and cross-entropy loss function. This enabled the network to be trained quickly without needing to rely on any high-level libraries for deep learning.\n",
        "\n",
        "The final model achieved test accuracies between 75% and 80%, surpassing the minimum performance requirement of 70%. In addition, the exercise allowed us to better understand how a fully connected neural network operates internally, including the forward pass, backpropagation and the decisions made during network creation."
      ],
      "metadata": {
        "id": "IPRONEKOFb2m"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}